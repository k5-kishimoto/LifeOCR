import os
import json
import io
import time
import re
import concurrent.futures
from pdf2image import convert_from_bytes
import google.generativeai as genai
from PIL import Image, ImageEnhance, ImageOps 
from dotenv import load_dotenv

load_dotenv()

class OcrEngine:
    def __init__(self):
        """åˆæœŸåŒ–: Gemini APIã®è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™"""
        self.api_key = os.environ.get("GEMINI_API_KEY")
        self.model = None
        
        if not self.api_key:
            print("âŒ Error: 'GEMINI_API_KEY' not found.")
            return

        try:
            genai.configure(api_key=self.api_key)
            self.model_name = os.environ.get("GEMINI_VERSION", "gemini-2.5-flash")
            
            # JSONãƒ¢ãƒ¼ãƒ‰è¨­å®š
            self.generation_config = genai.types.GenerationConfig(
                temperature=0.0, 
                top_p=1.0,
                max_output_tokens=8192,
                response_mime_type="application/json"
            )
            
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config
            )
            print(f"âš™ï¸ Initial Model config: {self.model_name} (Refactored Mode)")

        except Exception as e:
            print(f"âŒ API Configuration Error: {e}")

    # =========================================================================
    # ðŸ–¼ï¸ ç”»åƒå‡¦ç†é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _optimize_image(self, img):
        """ç”»åƒã‚’OCRå‘ã‘ã«æœ€é©åŒ–ï¼ˆãƒªã‚µã‚¤ã‚ºã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã€ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ï¼‰"""
        # ãƒ¡ãƒ¢ãƒªå¯¾ç­–: è§£åƒåº¦ã‚’2560pxã«åˆ¶é™
        max_size = 2560 
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # ã‚ªãƒ¼ãƒˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã§æ–‡å­—ã‚’ãã£ãã‚Šã•ã›ã‚‹
        img = ImageOps.autocontrast(img, cutoff=1)
        
        # ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹å¼·åŒ–ï¼ˆç´°ã„æ–‡å­—å¯¾ç­–ï¼‰
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.4) 
        
        return img

    def _split_image(self, img):
        """
        é•·ã„æ˜Žç´°æ›¸ã‚’èª­ã¿åˆ‡ã‚‹ãŸã‚ã«ã€ç”»åƒã‚’ä¸Šä¸‹ã«åˆ†å‰²ã™ã‚‹ã€‚
        å¢ƒç•Œç·šã®æ–‡å­—åˆ‡ã‚Œã‚’é˜²ããŸã‚ã€20%ã»ã©é‡è¤‡ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼‰ã•ã›ã‚‹ã€‚
        """
        width, height = img.size
        split_ratio = 0.60 # ä¸Šéƒ¨ã¯60%ã¾ã§
        overlap = 0.40     # ä¸‹éƒ¨ã¯40%ã‹ã‚‰é–‹å§‹ï¼ˆ20%é‡è¤‡ï¼‰
        
        crop_top = img.crop((0, 0, width, int(height * split_ratio)))
        crop_bottom = img.crop((0, int(height * overlap), width, height))
        
        return [("Top", crop_top), ("Bottom", crop_bottom)]

    # =========================================================================
    # ðŸ§  AIãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _repair_json(self, text):
        """å£Šã‚ŒãŸJSONæ–‡å­—åˆ—ã‚’å¯èƒ½ãªé™ã‚Šä¿®å¾©ã—ã¦è¾žæ›¸åž‹ã«å¤‰æ›ã™ã‚‹"""
        # 1. ã¾ãšæ¨™æº–çš„ãªãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
        try:
            cleaned = text.strip()
            if cleaned.startswith("```json"): cleaned = cleaned[7:-3]
            elif cleaned.startswith("```"): cleaned = cleaned[3:-3]
            return json.loads(cleaned)
        except:
            pass

        # 2. è»½å¾®ãªç ´æï¼ˆé–‰ã˜å¿˜ã‚Œï¼‰ã®ä¿®å¾©
        try:
            if cleaned.count('"') % 2 != 0: cleaned += '"'
            if not cleaned.endswith("}"): cleaned += "}]}"
            return json.loads(cleaned)
        except:
            pass
            
        # 3. æœ€çµ‚æ‰‹æ®µ: æ­£è¦è¡¨ç¾ã§ã€Œè¡Œãƒ‡ãƒ¼ã‚¿ã‚‰ã—ãã‚‚ã®ã€ã ã‘ã‚’æŠœãå‡ºã™
        try:
            rows = re.findall(r'\[\s*"(?:[^"\\]|\\.)*"(?:\s*,\s*"(?:[^"\\]|\\.)*")*\s*\]', text, re.DOTALL)
            if rows:
                valid_rows = []
                for r in rows:
                    try:
                        row_data = json.loads(r)
                        if isinstance(row_data, list): valid_rows.append(row_data)
                    except: pass
                if valid_rows:
                    return {"table_rows": valid_rows}
        except:
            pass

        return None

    def _call_ai_api(self, image_part, part_label):
        """Gemini APIã‚’å‘¼ã³å‡ºã™ï¼ˆãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãï¼‰"""
        prompt = """
        ã‚ãªãŸã¯é«˜ç²¾åº¦ã®æ—¥æœ¬èªžOCRã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚
        ç”»åƒã¯æ›¸é¡žã®ä¸€éƒ¨ï¼ˆä¸ŠåŠåˆ†ã¾ãŸã¯ä¸‹åŠåˆ†ï¼‰ã§ã™ã€‚
        è¦‹ãˆã¦ã„ã‚‹ç¯„å›²ã®ã™ã¹ã¦ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

        ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
        1. æ–‡å­—ç¨®ã®ç¶­æŒ: åŠè§’ã‚«ãƒŠ(`ï¾Œï¾˜ï½ºï¾`)ã¯åŠè§’ã®ã¾ã¾ã€‚å…¨è§’å¤‰æ›ç¦æ­¢ã€‚
        2. ç©ºç™½ã®ç¶­æŒ: æ°åã®é–“ã®ã‚¹ãƒšãƒ¼ã‚¹ã¯å‰Šé™¤ã—ãªã„ã€‚
        
        ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ (JSON)ã€‘
        {
          "document_info": { "bank_name": "éŠ€è¡Œå", "branch_name": "æ”¯åº—å", "title": "æ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«", "account_name": "å£åº§åç¾©", "period": "æœŸé–“", "other_info": "ãã®ä»–" },
          "table_headers": ["æ—¥ä»˜", "æ‘˜è¦", "ãŠæ”¯æ‰•é‡‘é¡", "ãŠé ã‚Šé‡‘é¡", "å·®å¼•æ®‹é«˜", "å–æ‰±åº—"],
          "table_rows": [ ["2026-01-22", "ï¾Œï¾˜ï½ºï¾ ï¾”ï¾ï¾€ï¾ž ï¾€ï¾›ï½³", "10,000", "", "50,000", "æœ¬åº—"] ]
        }
        """

        retry_models = [
            self.model_name,
            'gemini-2.5-pro',
            'gemini-2.0-flash'
        ]
        
        for current_model_name in retry_models:
            try:
                current_model = genai.GenerativeModel(
                    current_model_name,
                    generation_config=self.generation_config
                )
                response = current_model.generate_content([prompt, image_part])
                return response.text
            except Exception as e:
                print(f"âš ï¸ API Error ({part_label} - {current_model_name}): {e}")
                time.sleep(1)
                continue
        
        return None

    # =========================================================================
    # ðŸ”„ ãƒ‡ãƒ¼ã‚¿çµåˆãƒ»æ•´å½¢ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _merge_split_results(self, results):
        """Topã¨Bottomã®è§£æžçµæžœã‚’çµåˆã—ã€é‡è¤‡è¡Œã‚’å‰Šé™¤ã™ã‚‹"""
        combined_json = { "document_info": {}, "table_headers": [], "table_rows": [] }

        # 1. ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®å–å¾—ï¼ˆTopã‚’å„ªå…ˆï¼‰
        target_source = "Top" if "Top" in results else "Bottom"
        if target_source in results:
            combined_json["document_info"] = results[target_source].get("document_info", {})
            combined_json["table_headers"] = results[target_source].get("table_headers", [])

        # 2. è¡Œãƒ‡ãƒ¼ã‚¿ã®çµåˆ
        raw_rows = []
        if "Top" in results: raw_rows.extend(results["Top"].get("table_rows", []))
        if "Bottom" in results: raw_rows.extend(results["Bottom"].get("table_rows", []))

        # 3. é‡è¤‡è¡Œã®æŽ’é™¤ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—éƒ¨åˆ†ã®å‡¦ç†ï¼‰
        seen = set()
        unique_rows = []
        for row in raw_rows:
            # è¡Œã®ä¸­èº«ã‚’ã™ã¹ã¦çµåˆã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ä½œã‚‹
            row_vals = []
            for c in row:
                if isinstance(c, (dict, list)): row_vals.append(str(c))
                else: row_vals.append(str(c).strip())
            
            row_id = "".join(row_vals)
            
            # åˆã‚ã¦è¦‹ã‚‹è¡Œãªã‚‰æŽ¡ç”¨
            if row_id and row_id not in seen:
                seen.add(row_id)
                unique_rows.append(row)
        
        combined_json["table_rows"] = unique_rows
        return combined_json, len(unique_rows)

    def _format_to_ui_data(self, combined_json):
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªè¡¨ç¤ºç”¨ã®å½¢å¼ï¼ˆãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆï¼‰ã«å¤‰æ›ã™ã‚‹"""
        formatted_rows = []

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼: å®‰å…¨ãªæ–‡å­—åˆ—å¤‰æ›
        def safe_str(val):
            if val is None: return ""
            if isinstance(val, (dict, list)): return str(val)
            return str(val).strip()

        # 1. æ–‡æ›¸æƒ…å ±ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ»éŠ€è¡Œåãªã©ï¼‰
        doc_info = combined_json.get("document_info", {})
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_text = safe_str(doc_info.get('title')) or "æ˜Žç´°æ›¸"
        formatted_rows.append([{'text': f"â–  {title_text}", 'is_header': True}])
        
        # éŠ€è¡Œãƒ»æ”¯åº—
        bank_info = []
        if doc_info.get("bank_name"): bank_info.append(f"ðŸ¦ {safe_str(doc_info['bank_name'])}")
        if doc_info.get("branch_name"): bank_info.append(f"ðŸ¢ {safe_str(doc_info['branch_name'])}")
        if bank_info: formatted_rows.append([{'text': " ".join(bank_info)}])

        # å£åº§ãƒ»æœŸé–“ãªã©
        meta_texts = []
        if doc_info.get("account_name"): meta_texts.append(f"åç¾©: {safe_str(doc_info['account_name'])}")
        if doc_info.get("period"): meta_texts.append(f"æœŸé–“: {safe_str(doc_info['period'])}")
        if doc_info.get("other_info"): meta_texts.append(safe_str(doc_info['other_info']))
        if meta_texts: formatted_rows.append([{'text': " / ".join(meta_texts)}])
        
        formatted_rows.append([{'text': ""}]) # ç©ºè¡Œ

        # 2. è¡¨ãƒ˜ãƒƒãƒ€ãƒ¼
        headers = combined_json.get("table_headers", [])
        if headers:
            clean_headers = [safe_str(h) for h in headers]
            formatted_rows.append([{'text': h, 'is_header': True} for h in clean_headers])

        # 3. æ˜Žç´°ãƒ‡ãƒ¼ã‚¿
        for row in combined_json.get("table_rows", []):
            def clean_cell(val):
                if val is None: return ""
                if isinstance(val, (dict, list)): return str(val)
                s = str(val).strip()
                if s.lower() in ["null", "none"]: return ""
                return s

            if isinstance(row, list):
                formatted_cells = [{'text': clean_cell(cell)} for cell in row]
            else:
                formatted_cells = [{'text': clean_cell(row)}]
            formatted_rows.append(formatted_cells)

        return formatted_rows

    # =========================================================================
    # ðŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼
    # =========================================================================

    def _process_single_page(self, args):
        """1ãƒšãƒ¼ã‚¸åˆ†ã®å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆç”»åƒæœ€é©åŒ– -> åˆ†å‰² -> ä¸¦åˆ—OCR -> çµåˆ -> æ•´å½¢ï¼‰"""
        page_label, pil_image = args
        
        # 1. ç”»åƒã®æœ€é©åŒ–
        optimized_image = self._optimize_image(pil_image)
        
        # 2. ç”»åƒã®åˆ†å‰²ï¼ˆTop/Bottomï¼‰
        parts = self._split_image(optimized_image)
        
        # 3. ä¸¦åˆ—ã§AIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
        results = {}
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_to_part = {}
            for p_name, p_img in parts:
                # WebPå¤‰æ›
                img_byte_arr = io.BytesIO()
                p_img.save(img_byte_arr, format='WEBP', quality=85)
                image_part = {"mime_type": "image/webp", "data": img_byte_arr.getvalue()}
                
                future = executor.submit(self._call_ai_api, image_part, f"{page_label}-{p_name}")
                future_to_part[future] = p_name

            # çµæžœã®å›žåŽã¨ä¿®å¾©
            for future in concurrent.futures.as_completed(future_to_part):
                p_name = future_to_part[future]
                res_text = future.result()
                
                if res_text:
                    repaired_data = self._repair_json(res_text)
                    if repaired_data:
                        results[p_name] = repaired_data
                    else:
                        print(f"âŒ JSON Repair Failed for {p_name}")

        # 4. çµæžœã®çµåˆï¼ˆãƒžãƒ¼ã‚¸ï¼‰
        combined_json, row_count = self._merge_split_results(results)
        
        # 5. ã‚¢ãƒ—ãƒªè¡¨ç¤ºç”¨ã«æ•´å½¢
        formatted_rows = self._format_to_ui_data(combined_json)
        
        print(f"âœ… Success ({page_label}) - Merged {row_count} rows")
        return (page_label, formatted_rows)


    def extract_text(self, uploaded_file):
        """å¤–éƒ¨ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰"""
        print(f"â³ Starting Gemini AI OCR ({self.model_name}) - Refactored Mode...")
        
        if not self.model:
            return [[{'text': "Error: AI Model not initialized."}]]

        uploaded_file.seek(0)
        file_bytes = uploaded_file.read()
        
        try:
            filename = uploaded_file.name.lower()
        except AttributeError:
            filename = "unknown.jpg"
            
        images_to_process = [] 

        if filename.endswith('.pdf'):
            try:
                pil_images = convert_from_bytes(file_bytes, dpi=250, fmt='jpeg')
                for i, img in enumerate(pil_images):
                    images_to_process.append((f"Page {i+1}", img))
            except Exception as e:
                print(f"âŒ PDF Error: {e}")
                return [[{'text': f"PDF Error: {e}"}]]
        else:
            img = Image.open(io.BytesIO(file_bytes))
            images_to_process.append(("Page 1", img))

        final_results = []

        # ãƒšãƒ¼ã‚¸å˜ä½ã®ä¸¦åˆ—å‡¦ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_to_page = {executor.submit(self._process_single_page, item): item[0] for item in images_to_process}
            
            results_dict = {}
            for future in concurrent.futures.as_completed(future_to_page):
                page_label, page_data = future.result()
                results_dict[page_label] = page_data

        for label, _ in images_to_process:
            if len(images_to_process) > 1:
                final_results.append([{'text': f'--- {label} ---', 'is_header': True}])
            
            if label in results_dict:
                final_results.extend(results_dict[label])

        return final_results

engine = OcrEngine()