import os
import json
import io
import time
import re
import concurrent.futures
from pdf2image import convert_from_bytes
import google.generativeai as genai
from PIL import Image, ImageEnhance, ImageOps 
from dotenv import load_dotenv

load_dotenv()

class OcrEngine:
    def __init__(self):
        self.api_key = os.environ.get("GEMINI_API_KEY")
        self.model = None
        
        if not self.api_key:
            print("âŒ Error: 'GEMINI_API_KEY' not found.")
            return

        try:
            genai.configure(api_key=self.api_key)
            self.model_name = os.environ.get("GEMINI_VERSION", "gemini-2.5-flash")
            
            self.generation_config = genai.types.GenerationConfig(
                temperature=0.0, 
                top_p=1.0,
                max_output_tokens=8192,
                response_mime_type="application/json"
            )
            
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config
            )
            print(f"âš™ï¸ Initial Model config: {self.model_name} (Header-Focus Mode)")

        except Exception as e:
            print(f"âŒ API Configuration Error: {e}")

    def _optimize_image(self, img):
        # ç”»åƒã®å››éš…ã¾ã§ãã£ãã‚Šã•ã›ã‚‹ãŸã‚ã«é«˜è§£åƒåº¦ç¶­æŒ
        max_size = 3200 
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        img = ImageOps.autocontrast(img, cutoff=1)
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.3) 
        
        return img

    def _process_single_page(self, args):
        page_label, pil_image = args
        
        optimized_image = self._optimize_image(pil_image)
        
        img_byte_arr = io.BytesIO()
        optimized_image.save(img_byte_arr, format='WEBP', quality=100, lossless=True)
        img_bytes = img_byte_arr.getvalue()
        
        image_part = {"mime_type": "image/webp", "data": img_bytes}

        # â˜…ã“ã“ã‚’å¤§å¹…å¼·åŒ–ï¼šãƒ˜ãƒƒãƒ€ãƒ¼æŽ¢ç´¢ã®æŒ‡ç¤ºã‚’è¿½åŠ 
        prompt = """
        ã‚ãªãŸã¯é«˜ç²¾åº¦ã®æ—¥æœ¬èªžOCRã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚
        ç”»åƒã‹ã‚‰å…¨ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

        ã€æœ€é‡è¦ï¼šã‚¹ã‚­ãƒ£ãƒ³æ‰‹é †ã€‘
        1. **ãƒ˜ãƒƒãƒ€ãƒ¼é ˜åŸŸã®å®Œå…¨ã‚¹ã‚­ãƒ£ãƒ³**:
           - ã¾ãšã€**ç”»åƒã®æœ€ä¸Šéƒ¨ã€å·¦ä¸Šã€å³ä¸Š**ã‚’æ³¨æ„æ·±ãè¦‹ã¦ãã ã•ã„ã€‚
           - ã€Œãƒ­ã‚´ãƒžãƒ¼ã‚¯ã€ã‚„ã€Œå°ã•ãªæ–‡å­—ã€ã§æ›¸ã‹ã‚ŒãŸ **éŠ€è¡Œåãƒ»é‡‘èžæ©Ÿé–¢å** ã‚’å¿…ãšè¦‹ã¤ã‘å‡ºã—ã¦ãã ã•ã„ã€‚
           - ã€Œæ”¯åº—åã€ã‚„ã€Œå–æ‰±åº—ã€ã‚‚ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜è¿‘ã«ã‚ã‚‹å ´åˆãŒå¤šã„ã®ã§è¦‹é€ƒã•ãªã„ã§ãã ã•ã„ã€‚
        2. **è¡¨ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º**:
           - ãã®å¾Œã€ãƒ¡ã‚¤ãƒ³ã®è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚

        ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
        1. **æ–‡å­—ç¨®ã®ç¶­æŒ**: åŠè§’ã‚«ãƒŠ(`ï¾Œï¾˜ï½ºï¾`)ã¯åŠè§’ã®ã¾ã¾ã€‚å…¨è§’å¤‰æ›ç¦æ­¢ã€‚
        2. **ç©ºç™½ã®ç¶­æŒ**: æ°åã®é–“ã®ã‚¹ãƒšãƒ¼ã‚¹(`ï¾”ï¾ï¾€ï¾ž ï¾€ï¾›ï½³`)ã¯å‰Šé™¤ã—ãªã„ã€‚
        
        ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ (JSON)ã€‘
        {
          "document_info": {
             "bank_name": "éŠ€è¡Œåï¼ˆãƒ­ã‚´ã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰æŠ½å‡ºï¼‰",
             "branch_name": "æ”¯åº—åï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰",
             "title": "æ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå…¥å‡ºé‡‘æ˜Žç´°ãªã©ï¼‰",
             "account_name": "å£åº§åç¾©",
             "period": "æœŸé–“ãƒ»æ—¥ä»˜æƒ…å ±",
             "other_info": "ãã®ä»–ï¼ˆæ”¯åº—ã‚³ãƒ¼ãƒ‰ã‚„å£åº§ç•ªå·ãªã©ï¼‰"
          },
          "table_headers": ["æ—¥ä»˜", "æ‘˜è¦", "ãŠæ”¯æ‰•é‡‘é¡", "ãŠé ã‚Šé‡‘é¡", "å·®å¼•æ®‹é«˜", "å–æ‰±åº—"],
          "table_rows": [
             ["2026-01-22", "ï¾Œï¾˜ï½ºï¾ ï¾”ï¾ï¾€ï¾ž ï¾€ï¾›ï½³", "10,000", "", "50,000", "æœ¬åº—"]
          ]
        }
        """

        retry_models = [
            self.model_name,
            'gemini-2.5-pro',
            'gemini-2.0-flash'
        ]
        
        retry_models = list(dict.fromkeys(retry_models))

        for current_model_name in retry_models:
            try:
                current_model = genai.GenerativeModel(
                    current_model_name,
                    generation_config=self.generation_config
                )
                
                response = current_model.generate_content([prompt, image_part])
                raw_text = response.text
                
                formatted_rows = []

                try:
                    cleaned_text = raw_text.strip()
                    if cleaned_text.startswith("```json"):
                        cleaned_text = cleaned_text[7:-3]
                    elif cleaned_text.startswith("```"):
                        cleaned_text = cleaned_text[3:-3]

                    parsed_json = json.loads(cleaned_text)
                    
                    def safe_str(val):
                        if val is None: return ""
                        if isinstance(val, (dict, list)): return str(val)
                        return str(val).strip()

                    # 1. æ–‡æ›¸æƒ…å ±ï¼ˆéŠ€è¡Œåãƒ»æ”¯åº—åã‚’å¼·èª¿è¡¨ç¤ºï¼‰
                    doc_info = parsed_json.get("document_info", {})
                    
                    # ã‚¿ã‚¤ãƒˆãƒ«è¡Œ
                    title_text = safe_str(doc_info.get('title')) or "æ˜Žç´°æ›¸"
                    formatted_rows.append([{'text': f"â–  {title_text}", 'is_header': True}])
                    
                    # éŠ€è¡Œæƒ…å ±è¡Œï¼ˆã“ã“ã‚’ãƒªãƒƒãƒã«ã™ã‚‹ï¼‰
                    bank_info = []
                    if doc_info.get("bank_name"): bank_info.append(f"ðŸ¦ {safe_str(doc_info['bank_name'])}")
                    if doc_info.get("branch_name"): bank_info.append(f"ðŸ¢ {safe_str(doc_info['branch_name'])}")
                    
                    if bank_info:
                        formatted_rows.append([{'text': " ".join(bank_info)}])

                    # å£åº§ãƒ»ãã®ä»–æƒ…å ±è¡Œ
                    meta_texts = []
                    if doc_info.get("account_name"): meta_texts.append(f"åç¾©: {safe_str(doc_info['account_name'])}")
                    if doc_info.get("period"): meta_texts.append(f"æœŸé–“: {safe_str(doc_info['period'])}")
                    if doc_info.get("other_info"): meta_texts.append(safe_str(doc_info['other_info']))
                    
                    if meta_texts:
                        formatted_rows.append([{'text': " / ".join(meta_texts)}])
                    
                    # ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
                    formatted_rows.append([{'text': ""}])

                    # 2. ãƒ˜ãƒƒãƒ€ãƒ¼
                    headers = parsed_json.get("table_headers", [])
                    if headers:
                        clean_headers = [safe_str(h) for h in headers]
                        formatted_rows.append([{'text': h, 'is_header': True} for h in clean_headers])

                    # 3. ãƒ‡ãƒ¼ã‚¿
                    rows = parsed_json.get("table_rows", [])
                    for row in rows:
                        def clean_text(val):
                            if val is None: return ""
                            if isinstance(val, (dict, list)): return str(val)
                            s = str(val).strip() 
                            if s.lower() in ["null", "none"]: return ""
                            return s

                        if isinstance(row, list):
                            formatted_cells = [{'text': clean_text(cell)} for cell in row]
                        else:
                            formatted_cells = [{'text': clean_text(row)}]
                        formatted_rows.append(formatted_cells)

                except (json.JSONDecodeError, ValueError) as json_err:
                    print(f"âš ï¸ JSON Parse Error on {page_label}: {json_err}. Fallback.")
                    lines = raw_text.split('\n')
                    for line in lines:
                        if line.strip():
                            formatted_rows.append([{'text': line.strip()}])
                
                print(f"âœ… Success ({page_label}) with {current_model_name}")
                return (page_label, formatted_rows)

            except Exception as e:
                error_msg = str(e)
                print(f"âš ï¸ Failed ({page_label}) with {current_model_name}: {error_msg}")
                if "404" in error_msg or "not found" in error_msg or "429" in error_msg or "500" in error_msg:
                    continue
                else:
                    return (page_label, [[{'text': f"Error: {error_msg}"}]])

        return (page_label, [[{'text': "Failed to extract text."}]])


    def extract_text(self, uploaded_file):
        print(f"â³ Starting Gemini AI OCR ({self.model_name}) - Header-Focus Mode...")
        
        if not self.model:
            return [[{'text': "Error: AI Model not initialized."}]]

        uploaded_file.seek(0)
        file_bytes = uploaded_file.read()
        
        try:
            filename = uploaded_file.name.lower()
        except AttributeError:
            filename = "unknown.jpg"
            
        images_to_process = [] 

        if filename.endswith('.pdf'):
            try:
                pil_images = convert_from_bytes(file_bytes, dpi=300, fmt='jpeg')
                for i, img in enumerate(pil_images):
                    images_to_process.append((f"Page {i+1}", img))
            except Exception as e:
                print(f"âŒ PDF Error: {e}")
                return [[{'text': f"PDF Error: {e}"}]]
        else:
            img = Image.open(io.BytesIO(file_bytes))
            images_to_process.append(("Page 1", img))

        final_results = []

        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            future_to_page = {executor.submit(self._process_single_page, item): item[0] for item in images_to_process}
            
            results_dict = {}
            for future in concurrent.futures.as_completed(future_to_page):
                page_label, page_data = future.result()
                results_dict[page_label] = page_data

        for label, _ in images_to_process:
            if len(images_to_process) > 1:
                final_results.append([{'text': f'--- {label} ---', 'is_header': True}])
            
            if label in results_dict:
                final_results.extend(results_dict[label])

        return final_results

engine = OcrEngine()