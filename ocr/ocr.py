import os
import json
import io
import time
import re
import concurrent.futures
from pdf2image import convert_from_bytes
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from PIL import Image, ImageEnhance, ImageOps 
from dotenv import load_dotenv

load_dotenv()

class OcrEngine:
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.environ.get("GEMINI_API_KEY")
        self.model = None
        
        if not self.api_key:
            print("âŒ Error: 'GEMINI_API_KEY' not found.")
            return

        try:
            genai.configure(api_key=self.api_key)
            # å®‰å®šæ€§ã®é«˜ã„2.0-flashã‚’ä½¿ç”¨
            self.model_name = os.environ.get("GEMINI_VERSION", "gemini-2.0-flash")
            
            self.generation_config = genai.types.GenerationConfig(
                temperature=0.0, 
                top_p=1.0,
                max_output_tokens=8192,
                response_mime_type="application/json"
            )

            self.safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
            
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            print(f"âš™ï¸ Initial Model config: {self.model_name} (Rectangular-Output Mode)")

        except Exception as e:
            print(f"âŒ API Configuration Error: {e}")

    # =========================================================================
    # ğŸ§¹ ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
    # =========================================================================
    
    def _clean_text(self, val):
        if val is None: return ""
        val = str(val).replace("\n", "").replace("\r", "")
        # OCRç‰¹æœ‰ã®èª¤èªè­˜ãƒã‚¤ã‚ºã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«
        val = val.replace("â– ", " ").replace("â–¡", " ").replace("å›³", " ")
        return re.sub(r'\s+', ' ', val).strip()

    # =========================================================================
    # ğŸ–¼ï¸ ç”»åƒå‡¦ç†
    # =========================================================================

    def _optimize_image(self, img):
        max_size = 2560 
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img = ImageOps.autocontrast(img, cutoff=1)
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.3) 
        return img

    def _split_image(self, img):
        width, height = img.size
        split_ratio = 0.60
        overlap = 0.40 
        crop_top = img.crop((0, 0, width, int(height * split_ratio)))
        crop_bottom = img.crop((0, int(height * overlap), width, height))
        return [("Top", crop_top), ("Bottom", crop_bottom)]

    # =========================================================================
    # ğŸ§  ãƒ‡ãƒ¼ã‚¿è§£æ
    # =========================================================================

    def _repair_json(self, text):
        if not text: return None
        try:
            cleaned = text.strip()
            if cleaned.startswith("```json"): cleaned = cleaned[7:-3]
            elif cleaned.startswith("```"): cleaned = cleaned[3:-3]
            return json.loads(cleaned)
        except: pass
        
        try:
            candidate_rows = re.findall(r'\[(.*?)\]', text, re.DOTALL)
            valid_rows = []
            for row_content in candidate_rows:
                if not row_content.strip(): continue
                try:
                    row_data = json.loads(f"[{row_content}]")
                    if isinstance(row_data, list): valid_rows.append(row_data)
                except: pass
            if valid_rows: return {"table_rows": valid_rows}
        except: pass
        return None

    def _call_ai_api(self, image_part, part_label):
        prompt = """
        ã‚ãªãŸã¯æ—¥æœ¬èªOCRã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚ç”»åƒã‹ã‚‰è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        
        ã€å‘½ä»¤ã€‘
        - æ”¹è¡Œã‚³ãƒ¼ãƒ‰ç¦æ­¢ã€‚
        - åŠè§’ã‚«ãƒŠã¯ãã®ã¾ã¾ã€‚
        - é …ç›®åï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰ã‚‚ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã¨ã—ã¦ã€ä¸Šã‹ã‚‰é †ã«ã™ã¹ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

        ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (JSON)ã€‘
        {
          "document_info": { "line1": "ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ä»¥å¤–ã®æƒ…å ±" },
          "table_headers": ["é …ç›®1", "é …ç›®2", ...],
          "table_rows": [ 
             ["ãƒ‡ãƒ¼ã‚¿1", "ãƒ‡ãƒ¼ã‚¿2", "ãƒ‡ãƒ¼ã‚¿3", ...],
          ]
        }
        """
        try:
            response = self.model.generate_content([prompt, image_part])
            return response.text
        except Exception as e:
            print(f"âš ï¸ API Error ({part_label}): {e}")
            return None

    # =========================================================================
    # ğŸ”„ ãƒãƒ¼ã‚¸ & â˜…å®Œå…¨é•·æ–¹å½¢åŒ– (ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)
    # =========================================================================

    def _merge_and_pad(self, page_results):
        raw_output_list = []
        seen_exact_rows = set()

        for res in page_results:
            # 1. document_info (ã‚¿ã‚¤ãƒˆãƒ«ç­‰) ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            doc_info = res.get("document_info", {})
            for v in doc_info.values():
                if v: raw_output_list.append([self._clean_text(v)])

            # 2. table_headers ã‚’è¿½åŠ 
            headers = res.get("table_headers", [])
            if headers:
                raw_output_list.append([self._clean_text(h) for h in headers])

            # 3. table_rows ã‚’è¿½åŠ 
            for row in res.get("table_rows", []):
                if not row or all(str(c).strip() == "" for c in row): continue
                cleaned_row = [self._clean_text(c) for c in row]
                
                # æ–‡å­—åˆ—ã¨ã—ã¦å®Œå…¨ã«ä¸€è‡´ã™ã‚‹è¡Œã®ã¿é‡è¤‡æ’é™¤
                row_str = str(cleaned_row)
                if row_str not in seen_exact_rows:
                    seen_exact_rows.add(row_str)
                    raw_output_list.append(cleaned_row)

        if not raw_output_list: return []

        # â˜…ã€æ ¸å¿ƒã€‘æœ€å¤§åˆ—æ•°ã‚’ç®—å‡ºã—ã€å…¨è¡Œã‚’ãã®é•·ã•ã«æƒãˆã‚‹
        max_cols = max(len(row) for row in raw_output_list)
        max_cols = max(max_cols, 1)

        final_rows = []
        for row in raw_output_list:
            padded = row[:]
            while len(padded) < max_cols:
                padded.append("") # ç©ºã‚»ãƒ«ã‚’è¿½åŠ ã—ã¦é•·ã•ã‚’çµ±ä¸€
            final_rows.append([{'text': cell} for cell in padded])

        return final_rows

    # =========================================================================
    # ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†
    # =========================================================================

    def extract_text(self, uploaded_file):
        print(f"â³ Starting AI OCR - Strict Matrix Mode...")
        if not self.model: return [[{'text': "Error: AI Model not initialized."}]]

        uploaded_file.seek(0)
        file_bytes = uploaded_file.read()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®åˆ¤åˆ¥
        try:
            filename = uploaded_file.name.lower()
        except:
            filename = "unknown.jpg"

        pil_images = []
        try:
            if filename.endswith('.pdf'):
                pil_images = convert_from_bytes(file_bytes, dpi=200)
            else:
                pil_images = [Image.open(io.BytesIO(file_bytes))]
        except Exception as e:
            return [[{'text': f"âŒ File Recognition Error: {e}"}]]

        all_pages_output = []

        for i, img in enumerate(pil_images):
            page_label = f"Page {i+1}"
            optimized_img = self._optimize_image(img)
            parts = self._split_image(optimized_img)
            
            page_data_list = []
            for p_name, p_img in parts:
                img_byte_arr = io.BytesIO()
                p_img.save(img_byte_arr, format='WEBP')
                image_part = {"mime_type": "image/webp", "data": img_byte_arr.getvalue()}
                
                res_text = self._call_ai_api(image_part, f"{page_label}-{p_name}")
                if res_text:
                    parsed = self._repair_json(res_text)
                    if parsed: page_data_list.append(parsed)

            padded_page = self._merge_and_pad(page_data_list)
            if len(pil_images) > 1:
                all_pages_output.append([{'text': f"--- {page_label} ---"}] + ([{'text': ''}] * (len(padded_page[0])-1 if padded_page else 0)))
            all_pages_output.extend(padded_page)

        return all_pages_output

engine = OcrEngine()